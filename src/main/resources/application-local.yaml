spring:
  docker:
    compose:
      enabled: true
      stop.command: down
  datasource:
    url: jdbc:h2:file:~/chatmemory;AUTO_SERVER=true
    driver-class-name: org.h2.Driver
    username: sa
    password: password
  h2.console:
      enabled: true
      path: /h2-console
  jpa.hibernate.ddl-auto: update
  ai:
    chat.memory.repository.jdbc.schema: classpath:/schema/schema-h2db.sql
    chat.memory.repository.jdbc.initialize-schema: always
    ollama:
      base-url: http://localhost:11434
      chat:
        options:
          model: ${chat.client.modelName}
    vectorstore.qdrant:
        initialize-schema: true
        host: localhost
        port: 6334
        collection-name: vector_store

chat:
  client:
    modelName: "llama3.2:1b"
    temperature: 0.7
    maxTokens: 500
    topK: 3
    maxMessages: 10
    targetLanguage: "English"
    similarityThreshold: 0.2

logging:
  pattern:
    console: "%green(%d{HH:mm:ss.SSS}) %blue(%-5level) %red([%thread]) %yellow(%logger{15}) - %msg%n"
  level:
    root: INFO
    org.springframework.ai.chat.client.advisor: DEBUG
    org.springframework.ai.rag: DEBUG
    com.poc.ai: DEBUG

opentelemetry.exporter.otlp.endpoint: http://localhost:4317